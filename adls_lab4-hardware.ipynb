{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a href=\"https://deepwok.github.io/\">\n",
    "    <img src=\"../imgs/deepwok.png\" alt=\"Logo\" width=\"160\" height=\"160\">\n",
    "  </a>\n",
    "\n",
    "  <h1 align=\"center\">Lab 4 for Advanced Deep Learning Systems (ADLS) - Hardware Stream</h1>\n",
    "\n",
    "  <p align=\"center\">\n",
    "    ELEC70109/EE9-AML3-10/EE9-AO25\n",
    "    <br />\n",
    "\t\tWritten by\n",
    "    <a href=\"https://aaron-zhao123.github.io/\">Aaron Zhao, Pedro Gimenes </a>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General introduction\n",
    "\n",
    "In this lab, you will learn how to emit SystemVerilog code for a neural network that's been transformed and optimized by MASE. Then, you'll design some hardware for a new Pytorch layer, and simulate the hardware using your new module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hardware Emit pass\n",
    "\n",
    "The `emit_verilog` transform pass generates a top-level RTL file and testbench file according to the `MaseGraph`, which includes a hardware implementation of each layer in the network. This top-level file instantiates modules from the `components` library in MASE and/or modules generated using [HLS](https://en.wikipedia.org/wiki/High-level_synthesis), when internal components are not available. The hardware can then be simulated using [Verilator](https://www.veripool.org/verilator/), or deployed on an FPGA.\n",
    "\n",
    "First, add Machop to your system PATH (if you haven't already done so) and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bardia/code/adls/mase/machop\n"
     ]
    }
   ],
   "source": [
    "%cd mase/machop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bardia/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "        verilator --help\n",
      "        verilator --version\n",
      "        verilator --binary -j 0 [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --cc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --sc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --lint-only -Wall [source_files.v]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_hardware_metadata_analysis_pass,\n",
    "    report_node_type_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_cocotb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")\n",
    "\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n",
    "\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TO DO: remove\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "!verilator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the neural network. We're using a model which can be used to perform digit classification on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Toy FC model for digit recognition on MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll generate a MaseGraph and add metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bardia/.local/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/bardia/.local/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/bardia/.local/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/bardia/.local/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %flatten : [num_users=1] = call_function[target=torch.flatten](args = (%x,), kwargs = {start_dim: 1, end_dim: -1})\n",
      "    %fc1 : [num_users=1] = call_module[target=fc1](args = (%flatten,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%fc1,), kwargs = {inplace: False})\n",
      "    return relu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mg = MaseGraph(model=mlp)\n",
    "\n",
    "# Provide a dummy input for the graph so it can use for tracing\n",
    "batch_size = 1\n",
    "x = torch.randn((batch_size, 2, 2))\n",
    "dummy_in = {\"x\": x}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running `emit_verilog`, we'll quantize the model to fixed precision. Refer back to [lab 2](https://github.com/DeepWok/mase/blob/main/docs/labs/lab2.md) if you've forgotten how this works. Check that the data type for each node is correct after quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/bardia/code/adls/mase/machop/../../machop/configs/tests/quantize/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /home/bardia/code/adls/mase/machop/../../machop/configs/tests/quantize/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op     Mase type            Mase op      Value type\n",
      "-----------  -------------  -------------------  -----------  ------------\n",
      "x            placeholder    placeholder          placeholder  NA\n",
      "flatten      call_function  implicit_func        flatten      float\n",
      "fc1          call_module    module_related_func  linear       fixed\n",
      "relu         call_function  module_related_func  relu         fixed\n",
      "output       output         output               output       NA\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(\n",
    "    os.path.abspath(\"\"),\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"mase\",\n",
    "    \"machop\",\n",
    "    \"configs\",\n",
    "    \"tests\",\n",
    "    \"quantize\",\n",
    "    \"fixed.toml\",\n",
    ")\n",
    "with open(config_file, \"r\") as f:\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n",
    "\n",
    "# Update the metadata\n",
    "for node in mg.fx_graph.nodes:\n",
    "    for arg, arg_info in node.meta[\"mase\"][\"common\"][\"args\"].items():\n",
    "        if isinstance(arg_info, dict):\n",
    "            arg_info[\"type\"] = \"fixed\"\n",
    "            arg_info[\"precision\"] = [8, 3]\n",
    "    for result, result_info in node.meta[\"mase\"][\"common\"][\"results\"].items():\n",
    "        if isinstance(result_info, dict):\n",
    "            result_info[\"type\"] = \"fixed\"\n",
    "            result_info[\"precision\"] = [8, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's important to run the `add_hardware_metadata` analysis pass. This adds all the required metadata which is later used by the `emit_verilog` pass, including:\n",
    "\n",
    "1. The node's toolchain, which defines whether we use internal Verilog modules from the `components` library or the HLS flow.\n",
    "2. The Verilog parameters associated with each node.\n",
    "\n",
    "> **_TASK:_** Read [this page](https://jianyicheng.github.io/mase-tools/modules/analysis/add_metadata.html#add-hardware-metadata-analysis-pass) for more information on the hardware metadata pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bardia/code/adls/mase/machop\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg, _ = add_hardware_metadata_analysis_pass(mg, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the emit verilog pass to generate the SystemVerilog files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting Verilog...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting internal components...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bardia/.mase/top/hardware/rtl/top.sv\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_verilog_top_transform_pass(mg)\n",
    "mg, _ = emit_internal_rtl_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated files should now be found under `top/hardware`. \n",
    "\n",
    "> **_TASK:_** Read through `top/hardware/rtl/top.sv` and make sure you understand how our MLP model maps to this hardware design. \n",
    "\n",
    "You will notice the following instantiated modules:\n",
    "\n",
    "* `fixed_linear`: this is found under `components/linear/fixed_linear.sv` and implements each Linear layer in the model.\n",
    "* `fc<layer number>_weight/bias_source`: these are [BRAM](https://nandland.com/lesson-15-what-is-a-block-ram-bram/) memories which drive the weights and biases into the linear layers for computation.\n",
    "* `fixed_relu`: found under `components/activations/fixed_relu.sv`, implements the ReLU activation.\n",
    "\n",
    "As of now, we can't yet run a simulation on the model, as we haven't yet generated the memory components. To do this, run the `emit_bram` transform pass as follows, which will generate the memory initialization files and SystemVerilog modules to drive weights and biases into the linear layers. Finally, the `emit_verilog_tb` transform pass will generate the testbench files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting BRAM...\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: weight\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module weight successfully written into /home/bardia/.mase/top/hardware/rtl/fc1_weight_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data weight successfully written into /home/bardia/.mase/top/hardware/rtl/fc1_weight_rom.dat\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: bias\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module bias successfully written into /home/bardia/.mase/top/hardware/rtl/fc1_bias_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data bias successfully written into /home/bardia/.mase/top/hardware/rtl/fc1_bias_rom.dat\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_bram_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting testbench...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_cocotb_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_TASK:_** Now, you're ready to launch a simulation by calling the simulate action as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bardia/code/adls/mase/machop/top_cpy\n",
      "INFO: Running command perl /usr/local/bin/verilator -cc --exe -Mdir /home/bardia/code/adls/mase/machop/sim_build -DCOCOTB_SIM=1 --top-module top --vpi --public-flat-rw --prefix Vtop -o top -LDFLAGS '-Wl,-rpath,/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/libs -L/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/libs -lcocotbvpi_verilator' -Wno-fatal -Wno-lint -Wno-style --trace -I/home/bardia/code/adls/mase/machop/top_cpy/hardware/rtl -I/home/bardia/code/adls/mase/machop/mase_components/attention/rtl -I/home/bardia/code/adls/mase/machop/mase_components/sim/rtl -I/home/bardia/code/adls/mase/machop/mase_components/conv/rtl -I/home/bardia/code/adls/mase/machop/mase_components/axi/rtl -I/home/bardia/code/adls/mase/machop/mase_components/memory/rtl -I/home/bardia/code/adls/mase/machop/mase_components/cast/rtl -I/home/bardia/code/adls/mase/machop/mase_components/testbench/rtl -I/home/bardia/code/adls/mase/machop/mase_components/ViT/rtl -I/home/bardia/code/adls/mase/machop/mase_components/linear/rtl -I/home/bardia/code/adls/mase/machop/mase_components/fixed_arithmetic/rtl -I/home/bardia/code/adls/mase/machop/mase_components/float_arithmetic/rtl -I/home/bardia/code/adls/mase/machop/mase_components/arithmetic/rtl -I/home/bardia/code/adls/mase/machop/mase_components/common/rtl -I/home/bardia/code/adls/mase/machop/mase_components/matmul/rtl -I/home/bardia/code/adls/mase/machop/mase_components/activations/rtl -I/home/bardia/code/adls/mase/machop/mase_components/binary_arith/rtl -I/home/bardia/code/adls/mase/machop/mase_components/systolic_arrays/rtl -I/home/bardia/code/adls/mase/machop/mase_components/buffers/rtl /home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/share/lib/verilator/verilator.cpp /home/bardia/code/adls/mase/machop/top_cpy/hardware/rtl/top.sv in directory /home/bardia/code/adls/mase/machop/sim_build\n",
      "INFO: Running command make -C /home/bardia/code/adls/mase/machop/sim_build -f Vtop.mk in directory /home/bardia/code/adls/mase/machop/sim_build\n",
      "make: Entering directory '/home/bardia/code/adls/mase/machop/sim_build'\n",
      "make: Nothing to be done for 'default'.\n",
      "make: Leaving directory '/home/bardia/code/adls/mase/machop/sim_build'\n",
      "INFO: Running command /home/bardia/code/adls/mase/machop/sim_build/top in directory /home/bardia/code/adls/mase/machop/sim_build\n",
      "     -.--ns INFO     gpi                                ..mbed/gpi_embed.cpp:76   in set_program_name_in_venv        Did not detect Python virtual environment. Using system-wide Python interpreter\n",
      "     -.--ns INFO     gpi                                ../gpi/GpiCommon.cpp:101  in gpi_print_registered_impl       VPI registered\n",
      "     0.00ns INFO     cocotb                             Running on Verilator version 5.020 2024-01-01\n",
      "     0.00ns INFO     cocotb                             Running tests with cocotb v1.8.0 from /home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb\n",
      "     0.00ns INFO     cocotb                             Seeding Python random module with 1707414754\n",
      "     0.00ns CRITICAL cocotb.regression                  Failed to import module mase_top_tb: No module named 'chop'\n",
      "     0.00ns INFO     cocotb.regression                  MODULE variable was \"mase_top_tb\"\n",
      "     0.00ns INFO     cocotb.regression                  Traceback: \n",
      "     0.00ns INFO     cocotb.regression                  Traceback (most recent call last):\n",
      "                                                          File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/regression.py\", line 203, in _discover_tests\n",
      "                                                            module = _my_import(module_name)\n",
      "                                                          File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/regression.py\", line 72, in _my_import\n",
      "                                                            mod = __import__(name)\n",
      "                                                          File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/_pytest/assertion/rewrite.py\", line 186, in exec_module\n",
      "                                                            exec(co, module.__dict__)\n",
      "                                                          File \"/home/bardia/code/adls/mase/machop/top_cpy/hardware/test/mase_top_tb/__init__.py\", line 1, in <module>\n",
      "                                                            from .test import test\n",
      "                                                          File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/_pytest/assertion/rewrite.py\", line 186, in exec_module\n",
      "                                                            exec(co, module.__dict__)\n",
      "                                                          File \"/home/bardia/code/adls/mase/machop/top_cpy/hardware/test/mase_top_tb/test.py\", line 3, in <module>\n",
      "                                                            import chop\n",
      "                                                        ModuleNotFoundError: No module named 'chop'\n",
      "                                                        \n",
      "     0.00ns ERROR    gpi                                Passing event to upper layer failed\n",
      "INFO: Results file: /home/bardia/code/adls/mase/machop/sim_build/results.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/__init__.py\", line 233, in _initialise_testbench\n",
      "    _initialise_testbench_(argv_)\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/__init__.py\", line 316, in _initialise_testbench_\n",
      "    regression_manager = RegressionManager.from_discovery(top)\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/regression.py\", line 174, in from_discovery\n",
      "    return cls(dut, tests)\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/regression.py\", line 153, in __init__\n",
      "    for test in tests:\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/regression.py\", line 203, in _discover_tests\n",
      "    module = _my_import(module_name)\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/regression.py\", line 72, in _my_import\n",
      "    mod = __import__(name)\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/_pytest/assertion/rewrite.py\", line 186, in exec_module\n",
      "    exec(co, module.__dict__)\n",
      "  File \"/home/bardia/code/adls/mase/machop/top_cpy/hardware/test/mase_top_tb/__init__.py\", line 1, in <module>\n",
      "    from .test import test\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/_pytest/assertion/rewrite.py\", line 186, in exec_module\n",
      "    exec(co, module.__dict__)\n",
      "  File \"/home/bardia/code/adls/mase/machop/top_cpy/hardware/test/mase_top_tb/test.py\", line 3, in <module>\n",
      "    import chop\n",
      "ModuleNotFoundError: No module named 'chop'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bardia/miniconda3/envs/mase/lib/python3.10/site-packages/cocotb/__init__.py\", line 332, in _sim_event\n",
      "    scheduler.log.error(msg)\n",
      "AttributeError: 'NoneType' object has no attribute 'log'\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import simulate\n",
    "\n",
    "simulate(skip_build=False, skip_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `simulate` action creates a `dump.vcd` file within the `sim_build` directory, which contains the waveform trace of the simulation. The waveforms can be opened with a viewer like GTKWave.\n",
    "\n",
    "> **TASK**: Follow the instructions [here](https://gtkwave.sourceforge.net/) to install GTKWave on your platform, then open the generated trace file to inspect the signals in the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Task\n",
    "\n",
    "Pytorch has a number of layers which are available to users to define neural network models. At the moment, `emit_verilog` supports generating Verilog for models including Linear layers and the ReLU activation.\n",
    "\n",
    "> **_MAIN TASK:_** choose another layer type from the [Pytorch list](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) and write a SystemVerilog file to implement that layer in hardware. Then, change the generated `top.sv` file to inject that layer within the design. For example, you may replace the ReLU activations with [Leaky ReLU](https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html#torch.nn.RReLU). Re-run the simulation and observe the effect on latency and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
